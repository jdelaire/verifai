"""Tests for the scoring module -- confidence levels and verdict text."""

from __future__ import annotations

import pytest

from app.schemas import MetadataResult, ProvenanceResult
from app.scoring import build_report, compute_confidence, verdict_text

# ---------------------------------------------------------------------------
# Helpers to build fixtures quickly
# ---------------------------------------------------------------------------

def _meta(
    *,
    width: int = 1024,
    height: int = 768,
    fmt: str = "JPEG",
    has_exif: bool = True,
    camera: str | None = "Canon EOS R5",
    software: str | None = None,
) -> MetadataResult:
    return MetadataResult(
        has_exif=has_exif,
        camera_make_model=camera,
        software_tag=software,
        width=width,
        height=height,
        format=fmt,
    )


def _prov(
    *,
    present: bool = False,
    valid: bool | None = None,
    notes: list[str] | None = None,
) -> ProvenanceResult:
    return ProvenanceResult(
        c2pa_present=present,
        c2pa_valid=valid,
        notes=notes or [],
    )


# ---------------------------------------------------------------------------
# compute_confidence
# ---------------------------------------------------------------------------

class TestComputeConfidence:
    """Unit tests for compute_confidence()."""

    def test_none_likelihood_returns_low(self) -> None:
        assert compute_confidence(None, _meta(), _prov()) == "low"

    def test_small_image_returns_low(self) -> None:
        meta = _meta(width=100, height=100)
        assert compute_confidence(50, meta, _prov()) == "low"

    def test_screenshot_returns_low(self) -> None:
        meta = _meta(fmt="PNG", has_exif=False)
        assert compute_confidence(50, meta, _prov()) == "low"

    def test_screenshot_software_returns_low(self) -> None:
        meta = _meta(software="Snipping Tool", has_exif=True)
        assert compute_confidence(50, meta, _prov()) == "low"

    def test_ambiguous_no_signals_returns_low(self) -> None:
        meta = _meta(has_exif=False, camera=None)
        prov = _prov()
        assert compute_confidence(50, meta, prov) == "low"

    def test_high_score_good_quality_returns_high(self) -> None:
        meta = _meta()
        assert compute_confidence(95, meta, _prov()) == "high"

    def test_low_score_with_exif_returns_high(self) -> None:
        meta = _meta(has_exif=True)
        assert compute_confidence(5, meta, _prov()) == "high"

    def test_c2pa_valid_ai_returns_high(self) -> None:
        prov = _prov(present=True, valid=True, notes=["generated by AI model"])
        meta = _meta()
        assert compute_confidence(85, meta, prov) == "high"

    def test_moderate_score_returns_medium(self) -> None:
        meta = _meta(has_exif=True)
        assert compute_confidence(75, meta, _prov()) == "medium"

    def test_borderline_with_exif_returns_medium(self) -> None:
        meta = _meta(has_exif=True)
        assert compute_confidence(50, meta, _prov()) == "medium"


# ---------------------------------------------------------------------------
# verdict_text
# ---------------------------------------------------------------------------

class TestVerdictText:
    """Unit tests for verdict_text()."""

    def test_none_returns_unable(self) -> None:
        result = verdict_text(None)
        assert "Unable to determine" in result

    def test_high_score(self) -> None:
        assert verdict_text(95) == "This image is likely AI-generated."

    def test_eighty_boundary(self) -> None:
        assert verdict_text(80) == "This image is likely AI-generated."

    def test_moderate_high(self) -> None:
        assert "some indicators" in verdict_text(65)

    def test_sixty_boundary(self) -> None:
        assert "some indicators" in verdict_text(60)

    def test_inconclusive(self) -> None:
        assert "inconclusive" in verdict_text(45)

    def test_forty_boundary(self) -> None:
        assert "inconclusive" in verdict_text(40)

    def test_few_indicators(self) -> None:
        assert "few indicators" in verdict_text(25)

    def test_twenty_boundary(self) -> None:
        assert "few indicators" in verdict_text(20)

    def test_likely_authentic(self) -> None:
        assert verdict_text(10) == "This image is likely authentic."

    def test_zero(self) -> None:
        assert verdict_text(0) == "This image is likely authentic."


# ---------------------------------------------------------------------------
# build_report (integration-ish)
# ---------------------------------------------------------------------------

class TestBuildReport:
    """Verify that build_report assembles a coherent AnalysisReport."""

    def test_completed_status(self) -> None:
        report = build_report("job-1", 85, _meta(), _prov())
        assert report.status == "done"
        assert report.job_id == "job-1"
        assert report.ai_likelihood == 85

    def test_mandatory_limitations_always_present(self) -> None:
        report = build_report("job-2", 50, _meta(has_exif=True), _prov())
        assert len(report.limitations) >= 2
        assert any("false positives" in lim for lim in report.limitations)
        assert any("post-processing" in lim.lower() for lim in report.limitations)

    def test_none_likelihood_adds_extra_limitation(self) -> None:
        report = build_report("job-3", None, _meta(), _prov())
        assert any("unavailable" in lim for lim in report.limitations)

    def test_evidence_contains_score_line(self) -> None:
        report = build_report("job-4", 42, _meta(), _prov())
        assert any("42/100" in e for e in report.evidence)

    def test_evidence_no_score(self) -> None:
        report = build_report("job-5", None, _meta(), _prov())
        assert any("did not return" in e for e in report.evidence)
